{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data for noise\n",
    "This part of the code will be used to download noise data.\n",
    "\n",
    "It is based on Josh Russell's **fetch_NOISE**.\n",
    "\n",
    "*william b hawley april 2020*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import obspy\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy import UTCDateTime\n",
    "from obspy.geodetics import gps2dist_azimuth, locations2degrees\n",
    "from obspy.io.sac import SACTrace\n",
    "\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if data directory exists\n",
    "if not os.path.exists(NoiseDataDir):\n",
    "    os.makedirs(NoiseDataDir)\n",
    "\n",
    "# load the client\n",
    "client = Client(webservice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stations\n",
    "\n",
    "t1 = UTCDateTime(tstart)\n",
    "if isBeforeEvents == 1:\n",
    "    t1 = t1 - (60*60*24)*noDays\n",
    "t2 = UTCDateTime(tend)\n",
    "\n",
    "inventory = client.get_stations(network=network, station=','.join(StaList), channel=','.join(ChanList), starttime=t1, endtime=t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading noise for 2 days.\n"
     ]
    }
   ],
   "source": [
    "# Create file with days to download\n",
    "\n",
    "DayList = []\n",
    "if isBeforeEvents == 1:\n",
    "    # load event file\n",
    "    ifn = open(EventsFileName)\n",
    "    with open(DayFileName,'w') as f:\n",
    "        for line in ifn:\n",
    "            evDate = UTCDateTime(line)\n",
    "            if isCalDay == 1:\n",
    "                evDate = UTCDateTime(evDate.year,evDate.month,evDate.day)\n",
    "            for iday in range(1,noDays+1):\n",
    "                date = evDate-(60*60*24)*iday\n",
    "                date = datetime.strptime(str(date),'%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "                date = date.strftime('%Y%m%d%H%M')\n",
    "                f.write(date+'\\n')\n",
    "                DayList.append(date)\n",
    "elif isBeforeEvents == 0:\n",
    "    with open(DayFileName,'w') as f:\n",
    "        DayStart = UTCDateTime(t1.year,t1.month,t1.day)\n",
    "        DayEnd = UTCDateTime(t2.year,t2.month,t2.day)\n",
    "        iDay = DayStart\n",
    "        while iDay <= DayEnd:\n",
    "            date = datetime.strptime(str(iDay),'%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "            date = date.strftime('%Y%m%d%H%M')\n",
    "            f.write(date+'\\n')\n",
    "            DayList.append(date)\n",
    "            iDay += (60*60*24)\n",
    "\n",
    "f.close()\n",
    "print(\"Downloading noise for \"+str(len(DayList))+\" days.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on station BB030...\n",
      "Working on station BB060...\n"
     ]
    }
   ],
   "source": [
    "# Download data\n",
    "\n",
    "# loop through stations\n",
    "for ista in range(0,len(inventory[0])):\n",
    "    \n",
    "    # get station info\n",
    "    stel = inventory[0].stations[ista].elevation\n",
    "    stla = inventory[0].stations[ista].latitude\n",
    "    stlo = inventory[0].stations[ista].longitude\n",
    "    stnm = inventory[0].stations[ista].code\n",
    "    # make station file\n",
    "    print(\"Working on station \"+stnm+\"...\")\n",
    "    staDir = NoiseDataDir + network + '_' + stnm + '/'\n",
    "    if not os.path.exists(staDir):\n",
    "        os.makedirs(staDir)\n",
    "    \n",
    "    # loop through days in noise day file\n",
    "    for iday in DayList:\n",
    "        time1 = UTCDateTime(iday)\n",
    "        year = str(time1.year)\n",
    "        jday = str(\"{:03d}\".format(time1.julday))\n",
    "        hh = str(\"{:02d}\".format(time1.hour))\n",
    "        mm = str(\"{:02d}\".format(time1.minute))\n",
    "        ss = str(\"{:02d}\".format(time1.second))\n",
    "        time2 = time1 + (60*60*24)\n",
    "        \n",
    "        # loop through channels\n",
    "        for comp in ChanList:\n",
    "\n",
    "            # download\n",
    "            sac_out = staDir + stnm + '.' + year + '.' + jday + '.' + hh + '.' + mm + '.' + ss + '.' + comp + '.sac'\n",
    "            if os.path.exists(sac_out):\n",
    "                print(sac_out+\" already exists, skipping...\")\n",
    "                continue\n",
    "            try:\n",
    "                st = client.get_waveforms(network=network, station=stnm, location='*', channel=comp, starttime=time1, endtime=time2, attach_response=True)\n",
    "            except Exception:\n",
    "                print('Missing data for station: ',stnm)\n",
    "                continue\n",
    "\n",
    "            sr = st[0].stats.sampling_rate\n",
    "            \n",
    "            # check for gaps\n",
    "            if len(st) > 1:\n",
    "                st.merge(method=1, fill_value=0)\n",
    "            \n",
    "            # remove response\n",
    "            if isRemoveResp:\n",
    "                try:\n",
    "                    st.remove_response(output=RespOutput, zero_mean=ZeroMeanOpt, taper=TaperOpt, taper_fraction=TaperFraction, pre_filt=[LoFreq1, LoFreq2, sr/3, sr/2], water_level=60)\n",
    "                except Exception:\n",
    "                    print('Failed to remove response: ' + iday + 'for sta ' + stnm)\n",
    "                    continue\n",
    "\n",
    "            st.trim(starttime=time1, endtime=time2, pad=True, nearest_sample=False, fill_value=0) # make sure correct length\n",
    "            st.detrend(type='demean')\n",
    "            st.detrend(type='linear')\n",
    "            st.taper(type=\"cosine\",max_percentage=0.05)\n",
    "            \n",
    "            # downsample\n",
    "            if isDownsamp and sr!=srNew:\n",
    "                st.filter('lowpass', freq=0.4*srNew, zerophase=True) # anti-alias filter\n",
    "                st.decimate(factor=int(sr/srNew), no_filter=True) # downsample\n",
    "                st.detrend(type='demean')\n",
    "                st.detrend(type='linear')\n",
    "                st.taper(type=\"cosine\",max_percentage=0.05)\n",
    "\n",
    "            # convert to SAC and fill out station/event header info\n",
    "            sac = SACTrace.from_obspy_trace(st[0])\n",
    "            sac.stel = stel\n",
    "            sac.stla = stla\n",
    "            sac.stlo = stlo\n",
    "            sac.kcmpnm = comp\n",
    "            sac.delta = (1/srNew)\n",
    "            \n",
    "            # write sac file\n",
    "            sac_out = staDir + stnm + '.' + year + '.' + jday + '.' + hh + '.' + mm + '.' + ss + '.' + comp + '.sac'\n",
    "            sac.write(sac_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
